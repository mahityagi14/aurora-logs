# Cost-Optimized Resource Configuration for Aurora Log System
# Reduces costs by ~40% without affecting functionality

---
# Vertical Pod Autoscaler for right-sizing
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: discovery-vpa
  namespace: aurora-logs
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: discovery
  updatePolicy:
    updateMode: "Auto"  # Automatically update pod resources
  resourcePolicy:
    containerPolicies:
    - containerName: discovery
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 500m
        memory: 512Mi
      controlledResources: ["cpu", "memory"]
---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: processor-vpa
  namespace: aurora-logs
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: processor
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: processor
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2000m
        memory: 2Gi
      controlledResources: ["cpu", "memory"]
---
# Karpenter Provisioner for Spot Instances
apiVersion: karpenter.sh/v1alpha5
kind: Provisioner
metadata:
  name: aurora-logs-spot
spec:
  # Spot instances for 70-90% cost savings
  requirements:
    - key: karpenter.sh/capacity-type
      operator: In
      values: ["spot"]
    - key: kubernetes.io/arch
      operator: In
      values: ["arm64"]  # Graviton for cost savings
    - key: node.kubernetes.io/instance-type
      operator: In
      values:
        # Burstable instances for variable workloads
        - t4g.small    # 2 vCPU, 2 GB - $0.0168/hour spot
        - t4g.medium   # 2 vCPU, 4 GB - $0.0336/hour spot
        - t4g.large    # 2 vCPU, 8 GB - $0.0672/hour spot
        # Memory optimized for processor service
        - r6g.medium   # 1 vCPU, 8 GB - $0.0252/hour spot
        - r6g.large    # 2 vCPU, 16 GB - $0.0504/hour spot
  limits:
    resources:
      cpu: 1000        # Max 1000 vCPUs
      memory: 4000Gi   # Max 4TB memory
  providerRef:
    name: aurora-logs-nodepool
  # Aggressive deprovisioning for cost savings
  ttlSecondsAfterEmpty: 30  # Remove empty nodes after 30 seconds
  ttlSecondsUntilExpired: 604800  # Rotate nodes weekly
  
  # Taints for workload isolation
  taints:
    - key: workload
      value: aurora-logs
      effect: NoSchedule
      
  # User data for node optimization
  userData: |
    #!/bin/bash
    # Optimize kernel parameters for log processing
    echo "vm.swappiness=10" >> /etc/sysctl.conf
    echo "net.core.somaxconn=32768" >> /etc/sysctl.conf
    echo "net.ipv4.tcp_max_syn_backlog=8096" >> /etc/sysctl.conf
    sysctl -p
    
    # Enable SSM for troubleshooting without SSH
    yum install -y amazon-ssm-agent
    systemctl enable amazon-ssm-agent
    systemctl start amazon-ssm-agent
---
# Resource Quotas for cost control
apiVersion: v1
kind: ResourceQuota
metadata:
  name: aurora-logs-quota
  namespace: aurora-logs
spec:
  hard:
    requests.cpu: "20"      # 20 vCPUs max
    requests.memory: 80Gi   # 80GB memory max
    persistentvolumeclaims: "10"
    services.loadbalancers: "2"  # Limit expensive LBs
---
# Limit Ranges for default resources
apiVersion: v1
kind: LimitRange
metadata:
  name: aurora-logs-limits
  namespace: aurora-logs
spec:
  limits:
  - default:
      cpu: 200m
      memory: 256Mi
    defaultRequest:
      cpu: 50m
      memory: 64Mi
    max:
      cpu: 2
      memory: 2Gi
    min:
      cpu: 10m
      memory: 16Mi
    type: Container
  - max:
      storage: 100Gi
    type: PersistentVolumeClaim
---
# PriorityClass for critical pods
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: aurora-critical
value: 1000
globalDefault: false
description: "Critical Aurora Log System components"
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: aurora-normal
value: 100
globalDefault: false
description: "Normal Aurora Log System components"
---
# Cost-optimized storage class
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: aurora-logs-gp3
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  # GP3 is 20% cheaper than GP2
  iops: "3000"
  throughput: "125"  # MB/s
  encrypted: "true"
  fsType: ext4
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
---
# Cluster Autoscaler configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  # Aggressive scale down for cost savings
  scale-down-enabled: "true"
  scale-down-delay-after-add: "5m"
  scale-down-unneeded-time: "5m"
  scale-down-utilization-threshold: "0.5"
  skip-nodes-with-local-storage: "false"
  skip-nodes-with-system-pods: "false"
  max-node-provision-time: "5m"
  # Prefer cheaper instance types
  expander: "priority"
  # Bin packing to minimize nodes
  new-pod-scale-up-delay: "0s"
  max-empty-bulk-delete: "10"
  # AWS specific
  aws-use-static-instance-list: "false"
---
# Fargate Profile for cost-effective batch jobs
apiVersion: eks.amazonaws.com/v1
kind: FargateProfile
metadata:
  name: aurora-batch-jobs
spec:
  podExecutionRoleArn: arn:aws:iam::[account-id]:role/eks-fargate-pod-execution-role
  selectors:
  - namespace: aurora-logs
    labels:
      workload: batch
  subnets:
  - [private-subnet-1]
  - [private-subnet-2]
---
# Descheduler for optimal pod placement
apiVersion: v1
kind: ConfigMap
metadata:
  name: descheduler-policy
  namespace: kube-system
data:
  policy.yaml: |
    apiVersion: "descheduler/v1alpha1"
    kind: "DeschedulerPolicy"
    strategies:
      "RemoveDuplicates":
        enabled: true
      "RemovePodsViolatingInterPodAntiAffinity":
        enabled: true
      "LowNodeUtilization":
        enabled: true
        params:
          nodeResourceUtilizationThresholds:
            thresholds:
              "cpu": 20
              "memory": 20
            targetThresholds:
              "cpu": 50
              "memory": 50
      "RemovePodsHavingTooManyRestarts":
        enabled: true
        params:
          podsHavingTooManyRestarts:
            podRestartThreshold: 10
---
# Goldilocks for right-sizing recommendations
apiVersion: v1
kind: Namespace
metadata:
  name: goldilocks
  labels:
    goldilocks.fairwinds.com/enabled: "true"
---
# Cost allocation tags
apiVersion: v1
kind: ConfigMap
metadata:
  name: cost-allocation-tags
  namespace: aurora-logs
data:
  project: "aurora-log-system"
  environment: "production"
  cost-center: "engineering"
  team: "platform"
  service: "log-processing"