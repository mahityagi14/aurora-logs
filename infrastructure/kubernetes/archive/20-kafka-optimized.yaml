---
# Optimized single-node Kafka for cost efficiency
# Note: For true HA, you would need multi-node setup which triples costs
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-single-node
  namespace: aurora-logs
  labels:
    app: kafka
    variant: cost-optimized
spec:
  replicas: 1  # Single node for cost savings
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
        tier: messaging
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                - t3.medium  # Smallest instance that can handle Kafka
                - t3a.medium
      containers:
      - name: kafka
        image: aurora-kafka:latest
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "200m"     # Minimal CPU
            memory: "1Gi"   # Minimal memory
          limits:
            cpu: "500m"
            memory: "2Gi"
        env:
        # KRaft mode - no Zookeeper needed
        - name: KAFKA_CFG_NODE_ID
          value: "1"
        - name: KAFKA_CFG_PROCESS_ROLES
          value: "broker,controller"
        - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
          value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
        - name: KAFKA_CFG_LISTENERS
          value: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka-service.aurora-logs.svc.cluster.local:9092"
        - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
          value: "1@kafka-service.aurora-logs.svc.cluster.local:9093"
        
        # Performance optimizations for single node
        - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_MIN_INSYNC_REPLICAS
          value: "1"
        - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
          value: "1"
        
        # Memory optimizations
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx768M -Xms512M"  # Reduced heap
        - name: KAFKA_JVM_PERFORMANCE_OPTS
          value: "-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:+UseCompressedOops -XX:+UseStringDeduplication"
        
        # Log retention (1 day for cost savings)
        - name: KAFKA_CFG_LOG_RETENTION_HOURS
          value: "24"
        - name: KAFKA_CFG_LOG_RETENTION_BYTES
          value: "1073741824"  # 1GB per partition
        - name: KAFKA_CFG_LOG_SEGMENT_BYTES
          value: "134217728"   # 128MB segments
        
        # Compression
        - name: KAFKA_CFG_COMPRESSION_TYPE
          value: "lz4"  # Good balance of speed and compression
        
        # Optimized for Aurora logs workload
        - name: KAFKA_CFG_NUM_NETWORK_THREADS
          value: "2"
        - name: KAFKA_CFG_NUM_IO_THREADS
          value: "4"
        - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
          value: "102400"
        - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
          value: "102400"
        - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
          value: "104857600"
        
        ports:
        - name: kafka
          containerPort: 9092
        - name: controller
          containerPort: 9093
        
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka
        - name: kafka-config
          mountPath: /opt/bitnami/kafka/config/kraft
          
        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 60
          periodSeconds: 30
          
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - "/opt/bitnami/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092"
          initialDelaySeconds: 30
          periodSeconds: 10
          
        # Startup probe for slow starts
        startupProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 30
          
      volumes:
      - name: kafka-data
        persistentVolumeClaim:
          claimName: kafka-data-pvc
      - name: kafka-config
        emptyDir: {}
      
      # Init container to format storage
      initContainers:
      - name: kafka-init
        image: aurora-kafka:latest
        command:
        - sh
        - -c
        - |
          echo "Initializing Kafka storage..."
          KAFKA_CLUSTER_ID="MkU3OEVBNzE0QTI2Qjk2NA"
          /opt/bitnami/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /opt/bitnami/kafka/config/kraft/server.properties || true
          echo "Storage initialization complete"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka

---
# ConfigMap for Kafka topic creation
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-topics
  namespace: aurora-logs
data:
  create-topics.sh: |
    #!/bin/bash
    set -e
    
    KAFKA_BROKER="kafka-service.aurora-logs.svc.cluster.local:9092"
    
    echo "Waiting for Kafka to be ready..."
    until /opt/bitnami/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server $KAFKA_BROKER > /dev/null 2>&1; do
      echo "Kafka not ready, waiting..."
      sleep 5
    done
    
    echo "Creating optimized topics..."
    
    # Aurora logs topic - optimized settings
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-logs \
      --partitions 20 \
      --replication-factor 1 \
      --config retention.ms=86400000 \
      --config retention.bytes=1073741824 \
      --config compression.type=lz4 \
      --config segment.ms=3600000 \
      --config min.cleanable.dirty.ratio=0.5 \
      --if-not-exists
    
    # Dead letter queue
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-logs-dlq \
      --partitions 5 \
      --replication-factor 1 \
      --config retention.ms=604800000 \
      --config compression.type=lz4 \
      --if-not-exists
    
    # Metrics topic
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-metrics \
      --partitions 5 \
      --replication-factor 1 \
      --config retention.ms=21600000 \
      --config compression.type=lz4 \
      --if-not-exists
    
    echo "Topics created successfully!"
    
    # List topics
    /opt/bitnami/kafka/bin/kafka-topics.sh --list --bootstrap-server $KAFKA_BROKER

---
# Job to create topics
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-create-topics
  namespace: aurora-logs
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: kafka-topics
        image: aurora-kafka:latest
        command:
        - sh
        - /scripts/create-topics.sh
        volumeMounts:
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: scripts
        configMap:
          name: kafka-topics
          defaultMode: 0755