---
# Combined monitoring configuration for K8s logs and OpenObserve dashboards
# This file includes Fluent Bit DaemonSet for K8s log collection and dashboard configs

# ServiceAccount for Fluent Bit K8s log collector
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit-k8s
  namespace: aurora-logs
---
# ClusterRole for reading K8s logs
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluent-bit-k8s
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  - nodes
  verbs: ["get", "list", "watch"]
---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit-k8s
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit-k8s
subjects:
- kind: ServiceAccount
  name: fluent-bit-k8s
  namespace: aurora-logs
---
# ConfigMap for Fluent Bit K8s logs configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-k8s-config
  namespace: aurora-logs
data:
  fluent-bit.conf: |
    [SERVICE]
        Daemon Off
        Flush 1
        Log_Level info
        Parsers_File parsers.conf
        HTTP_Server On
        HTTP_Listen 0.0.0.0
        HTTP_Port 2020
        Health_Check On
        storage.path /var/log/flb-storage/
        storage.sync normal
        storage.checksum off
        storage.max_chunks_up 128
        storage.backlog.mem_limit 5M

    [INPUT]
        Name tail
        Path /var/log/containers/*_aurora-logs_*.log
        multiline.parser cri
        Tag kube.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
        Storage.type filesystem
        DB /var/log/flb_kube.db
        DB.locking true

    [FILTER]
        Name kubernetes
        Match kube.*
        Kube_URL https://kubernetes.default.svc:443
        Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix kube.var.log.containers.
        Merge_Log On
        Keep_Log Off
        K8S-Logging.Parser On
        K8S-Logging.Exclude Off
        Labels On
        Annotations Off

    [FILTER]
        Name modify
        Match kube.*
        Add _index k8s-logs
        Add _stream kubernetes
        Add _timestamp ${TIMESTAMP}

    [FILTER]
        Name lua
        Match kube.*
        script /fluent-bit/scripts/timestamp.lua
        call add_timestamp

    [OUTPUT]
        Name http
        Match kube.*
        Host openobserve-service.aurora-logs.svc.cluster.local
        Port 5080
        URI /api/default/k8s-logs/_json
        Format json
        Json_date_key _timestamp
        Json_date_format iso8601
        tls Off
        tls.verify Off
        net.keepalive on
        net.keepalive_idle_timeout 30
        compress gzip
        Header Authorization Basic YWRtaW5AZXhhbXBsZS5jb206Q29tcGxleHBhc3MjMTIz
        Header X-Scope-OrgID default
        Retry_Limit 5
        storage.total_limit_size 50M

    # Also send to S3 for long-term storage
    [OUTPUT]
        Name s3
        Match kube.*
        bucket aurora-log-system-k8s-logs
        region us-east-1
        use_put_object On
        total_file_size 50M
        upload_timeout 10m
        store_dir /tmp/fluent-bit/s3
        s3_key_format /k8s-logs/year=%Y/month=%m/day=%d/hour=%H/%{hostname}_%{uuid}.gz
        compression gzip
        content_type application/gzip

  parsers.conf: |
    [PARSER]
        Name cri
        Format regex
        Regex ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
        Time_Keep On

  timestamp.lua: |
    function add_timestamp(tag, timestamp, record)
        -- Ensure timestamp is in milliseconds for OpenObserve
        local ts_millis = math.floor(timestamp * 1000)
        record["_timestamp"] = ts_millis
        
        -- Add formatted timestamp
        record["@timestamp"] = os.date("!%Y-%m-%dT%H:%M:%S.000Z", timestamp)
        
        -- Add additional metadata
        if record["kubernetes"] then
            record["k8s_cluster"] = "aurora-cluster"
            record["k8s_region"] = "us-east-1"
        end
        
        return 1, timestamp, record
    end

---
# DaemonSet for Fluent Bit K8s log collector
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit-k8s
  namespace: aurora-logs
  labels:
    app: fluent-bit-k8s
spec:
  selector:
    matchLabels:
      app: fluent-bit-k8s
  template:
    metadata:
      labels:
        app: fluent-bit-k8s
    spec:
      serviceAccountName: fluent-bit-k8s
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      - key: node-role.kubernetes.io/control-plane
        effect: NoSchedule
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:3.2.2
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 20m
            memory: 100Mi
          limits:
            cpu: 100m
            memory: 200Mi
        env:
        - name: AWS_REGION
          value: "us-east-1"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
        - name: fluent-bit-scripts
          mountPath: /fluent-bit/scripts/
        - name: flb-storage
          mountPath: /var/log/flb-storage/
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-k8s-config
          items:
          - key: fluent-bit.conf
            path: fluent-bit.conf
          - key: parsers.conf
            path: parsers.conf
      - name: fluent-bit-scripts
        configMap:
          name: fluent-bit-k8s-config
          items:
          - key: timestamp.lua
            path: timestamp.lua
      - name: flb-storage
        emptyDir: {}
      - name: tmp
        emptyDir: {}
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
---
# ConfigMap for OpenObserve Dashboard configurations
apiVersion: v1
kind: ConfigMap
metadata:
  name: openobserve-dashboards
  namespace: aurora-logs
data:
  k8s-logs-dashboard.json: |
    {
      "version": 1,
      "title": "Kubernetes Logs Dashboard",
      "panels": [
        {
          "id": 1,
          "title": "Pod Logs by Namespace",
          "type": "logs",
          "gridPos": {"x": 0, "y": 0, "w": 24, "h": 8},
          "query": {
            "query": "SELECT * FROM k8s-logs WHERE kubernetes_namespace_name = 'aurora-logs' ORDER BY _timestamp DESC",
            "limit": 1000
          }
        },
        {
          "id": 2,
          "title": "Error Rate by Service",
          "type": "graph",
          "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8},
          "query": {
            "query": "SELECT kubernetes_labels_app as service, COUNT(*) as error_count FROM k8s-logs WHERE log LIKE '%ERROR%' GROUP BY service ORDER BY error_count DESC",
            "interval": "5m"
          }
        },
        {
          "id": 3,
          "title": "Pod Restarts",
          "type": "table",
          "gridPos": {"x": 12, "y": 8, "w": 12, "h": 8},
          "query": {
            "query": "SELECT kubernetes_pod_name, COUNT(*) as restart_count FROM k8s-logs WHERE log LIKE '%Back-off restarting failed container%' GROUP BY kubernetes_pod_name ORDER BY restart_count DESC"
          }
        },
        {
          "id": 4,
          "title": "Scaling Events",
          "type": "logs",
          "gridPos": {"x": 0, "y": 16, "w": 24, "h": 8},
          "query": {
            "query": "SELECT * FROM k8s-logs WHERE log LIKE '%scaled%' OR log LIKE '%HorizontalPodAutoscaler%' ORDER BY _timestamp DESC LIMIT 100"
          }
        }
      ]
    }

  aurora-logs-dashboard.json: |
    {
      "version": 1,
      "title": "Aurora Logs Processing Dashboard",
      "panels": [
        {
          "id": 1,
          "title": "Log Processing Rate",
          "type": "graph",
          "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
          "query": {
            "query": "SELECT COUNT(*) as logs_processed FROM aurora-logs WHERE _timestamp > now() - 1h GROUP BY time(1m)",
            "interval": "1m"
          }
        },
        {
          "id": 2,
          "title": "Processing Latency",
          "type": "graph",
          "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
          "query": {
            "query": "SELECT AVG(processing_time_ms) as avg_latency, MAX(processing_time_ms) as max_latency FROM aurora-logs WHERE _timestamp > now() - 1h GROUP BY time(1m)",
            "interval": "1m"
          }
        },
        {
          "id": 3,
          "title": "Error Logs by Database",
          "type": "table",
          "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8},
          "query": {
            "query": "SELECT db_instance, COUNT(*) as error_count FROM aurora-logs WHERE log_type = 'error' AND _timestamp > now() - 24h GROUP BY db_instance ORDER BY error_count DESC"
          }
        },
        {
          "id": 4,
          "title": "Slow Queries",
          "type": "table",
          "gridPos": {"x": 12, "y": 8, "w": 12, "h": 8},
          "query": {
            "query": "SELECT db_instance, query_time, query FROM aurora-logs WHERE log_type = 'slowquery' AND query_time > 1.0 ORDER BY query_time DESC LIMIT 20"
          }
        }
      ]
    }

  cost-optimization-dashboard.json: |
    {
      "version": 1,
      "title": "Cost Optimization Dashboard",
      "panels": [
        {
          "id": 1,
          "title": "Active Pods by Type",
          "type": "graph",
          "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
          "query": {
            "query": "SELECT kubernetes_labels_role as role, COUNT(DISTINCT kubernetes_pod_name) as pod_count FROM k8s-logs WHERE _timestamp > now() - 5m GROUP BY role, time(1m)",
            "interval": "1m"
          }
        },
        {
          "id": 2,
          "title": "Fargate vs EC2 Pods",
          "type": "piechart",
          "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
          "query": {
            "query": "SELECT kubernetes_annotations_eks_amazonaws_com_compute_type as compute_type, COUNT(DISTINCT kubernetes_pod_name) as count FROM k8s-logs WHERE _timestamp > now() - 5m GROUP BY compute_type"
          }
        },
        {
          "id": 3,
          "title": "Estimated Hourly Cost",
          "type": "stat",
          "gridPos": {"x": 0, "y": 8, "w": 24, "h": 8},
          "query": {
            "query": "SELECT SUM(CASE WHEN kubernetes_labels_role = 'master' THEN 0.01 WHEN kubernetes_labels_role = 'slave' THEN 0.0026 ELSE 0.005 END) as hourly_cost FROM (SELECT DISTINCT kubernetes_pod_name, kubernetes_labels_role FROM k8s-logs WHERE _timestamp > now() - 5m)"
          }
        }
      ]
    }

---
# Job to import dashboards into OpenObserve
apiVersion: batch/v1
kind: Job
metadata:
  name: import-dashboards
  namespace: aurora-logs
spec:
  template:
    spec:
      serviceAccountName: default
      restartPolicy: OnFailure
      containers:
      - name: dashboard-importer
        image: curlimages/curl:latest
        command:
        - sh
        - -c
        - |
          set -e
          OPENOBSERVE_URL="http://openobserve-service:5080"
          AUTH="admin@example.com:Complexpass#123"
          
          echo "Waiting for OpenObserve to be ready..."
          until curl -s -f -u "$AUTH" "$OPENOBSERVE_URL/api" > /dev/null; do
            echo "OpenObserve not ready, waiting..."
            sleep 10
          done
          
          echo "Creating K8s logs stream..."
          curl -X POST "$OPENOBSERVE_URL/api/default/k8s-logs/_create" \
            -u "$AUTH" \
            -H "Content-Type: application/json" \
            -d '{
              "name": "k8s-logs",
              "storage_type": "s3",
              "retention": 7,
              "partition_keys": ["kubernetes_namespace_name", "kubernetes_labels_app"],
              "full_text_search_keys": ["log", "message"],
              "index_prefix": "k8s-logs-"
            }'
          
          echo "Importing dashboards..."
          for dashboard in /dashboards/*.json; do
            echo "Importing $dashboard..."
            curl -X POST "$OPENOBSERVE_URL/api/default/dashboards" \
              -u "$AUTH" \
              -H "Content-Type: application/json" \
              -d "@$dashboard"
          done
          
          echo "Dashboard import complete!"
        volumeMounts:
        - name: dashboards
          mountPath: /dashboards
      volumes:
      - name: dashboards
        configMap:
          name: openobserve-dashboards