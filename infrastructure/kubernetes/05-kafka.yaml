---
# Optimized single-node Kafka for cost efficiency
# Note: For true HA, you would need multi-node setup which triples costs
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  namespace: aurora-logs
  labels:
    app: kafka
    component: message-broker
spec:
  replicas: 1  # Single node for cost savings
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
        tier: messaging
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      # Deploy only on aurora-node-2
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: eks.amazonaws.com/nodegroup
                operator: In
                values:
                - aurora-node-2
      containers:
      - name: kafka
        image: bitnami/kafka:4.0.0
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "200m"     # Minimal CPU
            memory: "1Gi"   # Minimal memory
          limits:
            cpu: "500m"
            memory: "2Gi"
        env:
        # Bitnami Kafka KRaft configuration
        - name: BITNAMI_DEBUG
          value: "true"
        - name: KAFKA_ENABLE_KRAFT
          value: "yes"
        - name: KAFKA_CFG_NODE_ID
          value: "1"
        - name: KAFKA_CFG_PROCESS_ROLES
          value: "controller,broker"
        - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
          value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
        - name: KAFKA_CFG_LISTENERS
          value: "PLAINTEXT://:9092,CONTROLLER://:9093"
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka-service.aurora-logs.svc.cluster.local:9092"
        - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
          value: "1@localhost:9093"
        - name: KAFKA_KRAFT_CLUSTER_ID
          value: "MkU3OEVBNzE0QTI2Qjk2NA"
        - name: ALLOW_PLAINTEXT_LISTENER
          value: "yes"
        
        # Performance optimizations for single node
        - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_MIN_INSYNC_REPLICAS
          value: "1"
        - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
          value: "1"
        
        # Memory optimizations
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx768M -Xms512M"  # Reduced heap
        - name: KAFKA_JVM_PERFORMANCE_OPTS
          value: "-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:+UseCompressedOops -XX:+UseStringDeduplication"
        
        # Log retention (1 day for cost savings)
        - name: KAFKA_CFG_LOG_RETENTION_HOURS
          value: "24"
        - name: KAFKA_CFG_LOG_RETENTION_BYTES
          value: "1073741824"  # 1GB per partition
        - name: KAFKA_CFG_LOG_SEGMENT_BYTES
          value: "134217728"   # 128MB segments
        
        # Compression
        - name: KAFKA_CFG_COMPRESSION_TYPE
          value: "lz4"  # Good balance of speed and compression
        
        # Optimized for Aurora logs workload
        - name: KAFKA_CFG_NUM_NETWORK_THREADS
          value: "2"
        - name: KAFKA_CFG_NUM_IO_THREADS
          value: "4"
        - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
          value: "102400"
        - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
          value: "102400"
        - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
          value: "104857600"
        
        ports:
        - name: kafka
          containerPort: 9092
        - name: controller
          containerPort: 9093
        
        volumeMounts:
        - name: kafka-data
          mountPath: /bitnami/kafka
          
        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 60
          periodSeconds: 30
          
        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          
        # Startup probe for slow starts
        startupProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 30
          
      volumes:
      - name: kafka-data
        persistentVolumeClaim:
          claimName: kafka-data-pvc
      
      # Init container to format storage
      # No init container needed for Bitnami Kafka - it handles initialization automatically

---
# Kafka Service
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  namespace: aurora-logs
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    targetPort: 9092
    name: kafka
  - port: 9093
    targetPort: 9093
    name: controller
  selector:
    app: kafka
  type: ClusterIP
---
# ConfigMap for Kafka topic creation
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-topics
  namespace: aurora-logs
data:
  create-topics.sh: |
    #!/bin/bash
    set -e
    
    KAFKA_BROKER="kafka-service.aurora-logs.svc.cluster.local:9092"
    
    echo "Waiting for Kafka to be ready..."
    until /opt/bitnami/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server $KAFKA_BROKER > /dev/null 2>&1; do
      echo "Kafka not ready, waiting..."
      sleep 5
    done
    
    echo "Creating optimized topics..."
    
    # Aurora error logs topic
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-error-logs \
      --partitions 10 \
      --replication-factor 1 \
      --config retention.ms=172800000 \
      --config retention.bytes=1073741824 \
      --config compression.type=lz4 \
      --config segment.ms=3600000 \
      --if-not-exists
    
    # Aurora slowquery logs topic
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-slowquery-logs \
      --partitions 10 \
      --replication-factor 1 \
      --config retention.ms=86400000 \
      --config retention.bytes=1073741824 \
      --config compression.type=lz4 \
      --config segment.ms=3600000 \
      --if-not-exists
    
    # Dead letter queue for error logs
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-error-logs-dlq \
      --partitions 3 \
      --replication-factor 1 \
      --config retention.ms=604800000 \
      --config compression.type=lz4 \
      --if-not-exists
    
    # Dead letter queue for slowquery logs
    /opt/bitnami/kafka/bin/kafka-topics.sh --create \
      --bootstrap-server $KAFKA_BROKER \
      --topic aurora-slowquery-logs-dlq \
      --partitions 3 \
      --replication-factor 1 \
      --config retention.ms=604800000 \
      --config compression.type=lz4 \
      --if-not-exists
    
    echo "Topics created successfully!"
    
    # List topics
    /opt/bitnami/kafka/bin/kafka-topics.sh --list --bootstrap-server $KAFKA_BROKER

---
# Job to create topics
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topics
  namespace: aurora-logs
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: kafka-topics
        image: bitnami/kafka:4.0.0
        command:
        - sh
        - /scripts/create-topics.sh
        volumeMounts:
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: scripts
        configMap:
          name: kafka-topics
          defaultMode: 0755